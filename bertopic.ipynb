{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1ef591b-73d1-41a4-a76f-34c211bac777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import umap\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba366bc5-6a2c-46c7-a80a-9fe9ca8d7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    AdamW,\n",
    "    glue_convert_examples_to_features,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bad686f-569e-4fa0-9ab5-ce71f2e162e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('./huggingface_model/', from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ee48bb8-bf90-4048-86cd-f25929cd55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('digitalepidemiologylab/covid-twitter-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62eccea7-6bf1-4849-8e5a-598441bd2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d432463-9b44-47db-8f1a-53eeb172014b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344688894038695939</td>\n",
       "      <td>0</td>\n",
       "      <td>We are excited to receive news that we will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344689204899565571</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris Rock excited to get the COVID vaccine: ‘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344689375079247872</td>\n",
       "      <td>0</td>\n",
       "      <td>If you're still excited about the new year, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344689636615073793</td>\n",
       "      <td>1</td>\n",
       "      <td>A new strain, more contagious....yet the same ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344689691052838915</td>\n",
       "      <td>0</td>\n",
       "      <td>Covid vaccine first dose: done! Excited to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687</th>\n",
       "      <td>1413118303283810311</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooh! Potential #CoronaVac by side-effect: I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12688</th>\n",
       "      <td>1413142807024336909</td>\n",
       "      <td>0</td>\n",
       "      <td>This rocks, very excited to get the vaccine as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12689</th>\n",
       "      <td>1413143486568681478</td>\n",
       "      <td>0</td>\n",
       "      <td>We're excited to announce a COVID-19 vaccinati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12690</th>\n",
       "      <td>1413129569662554117</td>\n",
       "      <td>0</td>\n",
       "      <td>Dec 2020: MOH: Vaccines are here! FPs: Yay! We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12691</th>\n",
       "      <td>1413112289935253505</td>\n",
       "      <td>1</td>\n",
       "      <td>Fauci to #unvaccinated Americans: “get over th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id  label  \\\n",
       "0      1344688894038695939      0   \n",
       "1      1344689204899565571      0   \n",
       "2      1344689375079247872      0   \n",
       "3      1344689636615073793      1   \n",
       "4      1344689691052838915      0   \n",
       "...                    ...    ...   \n",
       "12687  1413118303283810311      0   \n",
       "12688  1413142807024336909      0   \n",
       "12689  1413143486568681478      0   \n",
       "12690  1413129569662554117      0   \n",
       "12691  1413112289935253505      1   \n",
       "\n",
       "                                                    text  \n",
       "0      We are excited to receive news that we will be...  \n",
       "1      Chris Rock excited to get the COVID vaccine: ‘...  \n",
       "2      If you're still excited about the new year, yo...  \n",
       "3      A new strain, more contagious....yet the same ...  \n",
       "4      Covid vaccine first dose: done! Excited to be ...  \n",
       "...                                                  ...  \n",
       "12687  Ooh! Potential #CoronaVac by side-effect: I'm ...  \n",
       "12688  This rocks, very excited to get the vaccine as...  \n",
       "12689  We're excited to announce a COVID-19 vaccinati...  \n",
       "12690  Dec 2020: MOH: Vaccines are here! FPs: Yay! We...  \n",
       "12691  Fauci to #unvaccinated Americans: “get over th...  \n",
       "\n",
       "[12692 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeled/labeled.tsv', sep = '\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06ee9846-3a0b-4e18-9c54-0715a777d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].to_list(), df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ada53a10-52ee-4db6-b421-3e2c83f9a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b35c449c-02d4-462b-aead-9593590d6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for sent in X_train:\n",
    "    s = \"\"\n",
    "    for w in sent.lower().split():\n",
    "        if w not in stop_words:\n",
    "            s = s + \" \" + w\n",
    "    s = re.sub(pattern='^ +', repl='', string=s)\n",
    "    text.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aa8ead1-01d7-4c47-9e05-6e76efdea4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pipe(text, batch_size=128, truncation=\"only_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f4fe59b-db0d-47b2-a9e6-eb0c83f6b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = [np.mean(e[0], axis=0) for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "018034e2-ee6b-4905-acbe-021510da5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings = umap.UMAP(n_neighbors=15, \n",
    "                            n_components=5, \n",
    "                            metric='cosine').fit_transform(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56baa3f0-4324-49fa-b270-701bfc192912",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(min_cluster_size=15,\n",
    "                          metric='euclidean',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8437f6c7-5b84-482a-854f-507ff0d51b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_data = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine').fit_transform(emb)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e10388f-fa7b-4a9a-bc71-ec50b4d1290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['antivax'] = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9bdd700-db0b-408e-a18a-4e83f5ed2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('bertopic_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64061e7b-b6fe-45a4-8694-ab01915f6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(X_train, columns=[\"Doc\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7525e2d3-9ec2-40d5-8677-df8aa6951992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "  \n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a30ab617-fa11-4fcd-bdec-f8214f9e3b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shengtai/venv/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Size\n",
       "5      4  6533\n",
       "4      3  3514\n",
       "0     -1    41\n",
       "2      1    24\n",
       "3      2    22\n",
       "1      0    19"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4efa50a-6e07-4e07-8e88-715f7e6deca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('free', 0.32796258150643554),\n",
       " ('nomandates', 0.24095186202919094),\n",
       " ('noforcedcovidvaccines', 0.24095186202919094),\n",
       " ('belong', 0.24095186202919094),\n",
       " ('unconstitutional', 0.23879733201748557),\n",
       " ('unethical', 0.23482587133858748),\n",
       " ('tracked', 0.22493630926331618),\n",
       " ('mandates', 0.22214288237503843),\n",
       " ('bodies', 0.2208201496992256),\n",
       " ('choose', 0.21954226415934402)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53cd52f8-e9ac-4721-a519-7775780ba930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('incarceration', 0.28126645924007565),\n",
       " ('licenses', 0.28126645924007565),\n",
       " ('ubiquitous', 0.28126645924007565),\n",
       " ('isolation', 0.2756041029988635),\n",
       " ('pointless', 0.27386107580286856),\n",
       " ('universal', 0.27386107580286856),\n",
       " ('movement', 0.2689950278909609),\n",
       " ('worst', 0.2568778028251933),\n",
       " ('passports', 0.2492536376479497),\n",
       " ('completely', 0.2463357365690436)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd859421-f4c7-4938-891b-92bd77630383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excuse', 0.6483243386689037),\n",
       " ('herd', 0.6261577089892524),\n",
       " ('using', 0.5360632085501423),\n",
       " ('immunity', 0.519847734572914),\n",
       " ('kids', 0.5149098787563685),\n",
       " ('therapy', 0.27972714812633453),\n",
       " ('gene', 0.2763384846640605),\n",
       " ('voodoo', 0.04714020622508993),\n",
       " ('growth', 0.04331066379105709),\n",
       " ('tea', 0.042077826490978576)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66a36918-7434-4764-95d7-3faae088def2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experimental', 0.04287535124971336),\n",
       " ('gene', 0.03702586690966361),\n",
       " ('therapy', 0.0362531361161765),\n",
       " ('depopulation', 0.02636350389124544),\n",
       " ('people', 0.026053136693860016),\n",
       " ('covid', 0.024432943000661463),\n",
       " ('vaccines', 0.023302585525732195),\n",
       " ('mrna', 0.02132436977416879),\n",
       " ('virus', 0.01941517869809748),\n",
       " ('untested', 0.018342466594300503)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[3][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "873d4fdc-38c8-4136-8c28-046bb8e7a87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('got', 0.04081448407990466),\n",
       " ('dose', 0.0368480942854966),\n",
       " ('vaccinated', 0.03203865787898253),\n",
       " ('worry', 0.0308963590418855),\n",
       " ('today', 0.029836231125362517),\n",
       " ('covid', 0.029479925221600305),\n",
       " ('second', 0.027756822383957536),\n",
       " ('just', 0.027213762325878788),\n",
       " ('don', 0.026754458065144093),\n",
       " ('grateful', 0.026472424097737878)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[4][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4c2975e-8084-425e-be79-1fbe77fb3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_df = pd.read_csv('labeled/mom_post_label.csv', encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "51369720-38a5-401a-bb7f-738211b64b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_df = mom_df[mom_df['antivax'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b187f1d9-6258-4768-ae4a-0d625b996ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    27\n",
       "1.0     8\n",
       "Name: antivax, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom_df['antivax'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "88a93992-eb31-42cc-abd8-eae9af9b7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small function only used for formatting the output\n",
    "def format_prediction(preds, label_mapping, label_name):\n",
    "    preds = tf.nn.softmax(preds.detach(), axis=1)\n",
    "    formatted_preds = []\n",
    "    for pred in preds.numpy():\n",
    "        # convert to Python types and sort\n",
    "        pred = {label: float(probability) for label, probability in zip(label_mapping.values(), pred)}\n",
    "        pred = {k: v for k, v in sorted(pred.items(), key=lambda item: item[1], reverse=True)}\n",
    "        formatted_preds.append({label_name: list(pred.keys())[0], f'{label_name}_probabilities': pred})\n",
    "    return formatted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc8ee872-51fc-439b-9e77-0be045396753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(96, 1024), dtype=float32, numpy=\n",
       "array([[0.00014324, 0.0006547 , 0.00025379, ..., 0.00201751, 0.00134345,\n",
       "        0.00074256],\n",
       "       [0.00030995, 0.00067512, 0.00086431, ..., 0.00237262, 0.00112358,\n",
       "        0.00120067],\n",
       "       [0.00053847, 0.00178776, 0.00171518, ..., 0.00288228, 0.00117129,\n",
       "        0.00028236],\n",
       "       ...,\n",
       "       [0.00034234, 0.00216193, 0.00021207, ..., 0.00135204, 0.0006121 ,\n",
       "        0.00072489],\n",
       "       [0.00018248, 0.00033556, 0.00022555, ..., 0.0005103 , 0.00141485,\n",
       "        0.00126999],\n",
       "       [0.00014324, 0.00065471, 0.00025379, ..., 0.00201749, 0.00134341,\n",
       "        0.00074256]], dtype=float32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(preds[0][0].detach(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4066616d-c611-40a2-850b-534d68a7acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the labels for printing\n",
    "label_mapping = {\n",
    "    \"0\": 0,\n",
    "    \"1\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fd11f3e8-991a-4bc6-9a91-7e1713af8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 96 #@param {type: \"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "07e100b9-05df-4ed3-b87d-d9ce1d73081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fn(text_list):\n",
    "  #將text_list embedding成bert模型可用的輸入形式\n",
    "  #text_list:['我愛你','貓不是狗']\n",
    "    t_tokenizer = tokenizer(\n",
    "        text_list,\n",
    "        padding = True,\n",
    "        truncation = True,\n",
    "        max_length = max_seq_length,\n",
    "        return_tensors='tf'  # 返回的型別為pytorch tensor\n",
    "    )\n",
    "    input_ids = t_tokenizer['input_ids']\n",
    "    token_type_ids = t_tokenizer['token_type_ids']\n",
    "    attention_mask = t_tokenizer['attention_mask']\n",
    "    return input_ids, token_type_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdb61368-1a86-4db1-8f90-37121df28b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, _, _ = encode_fn(mom_df['Message'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ec9fc509-9588-4d45-88e6-cef5169592d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8614477-5d9e-44af-8503-111c97858080",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'antivax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8b36e0c7-9e36-4d06-bf85-d54adf72340a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_276804/2251068269.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mformatted_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'antivax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_276804/255826144.py\u001b[0m in \u001b[0;36mformat_prediction\u001b[0;34m(preds, label_mapping, label_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# convert to Python types and sort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mformatted_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{label_name}_probabilities'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_276804/255826144.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# convert to Python types and sort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mformatted_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{label_name}_probabilities'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "formatted_preds = format_prediction(preds[0], label_mapping, 'antivax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "48882828-77ee-4861-ab68-af180c55e0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(36, 96, 1024), dtype=float32, numpy=\n",
       "array([[[0.00415969, 0.00924361, 0.00364814, ..., 0.02224816,\n",
       "         0.01136238, 0.01898837],\n",
       "        [0.00791513, 0.0083819 , 0.01092547, ..., 0.0230077 ,\n",
       "         0.00835636, 0.02699903],\n",
       "        [0.01345911, 0.02172535, 0.02122122, ..., 0.02735737,\n",
       "         0.00852646, 0.00621477],\n",
       "        ...,\n",
       "        [0.00879401, 0.02700099, 0.00269667, ..., 0.01318887,\n",
       "         0.0045794 , 0.01639715],\n",
       "        [0.00463676, 0.00414553, 0.00283692, ..., 0.00492395,\n",
       "         0.01047049, 0.0284161 ],\n",
       "        [0.00415973, 0.00924374, 0.00364814, ..., 0.02224805,\n",
       "         0.0113621 , 0.01898838]],\n",
       "\n",
       "       [[0.00498838, 0.02577468, 0.00342259, ..., 0.01112231,\n",
       "         0.01365386, 0.01257421],\n",
       "        [0.01687934, 0.01438432, 0.02723755, ..., 0.00639525,\n",
       "         0.01161274, 0.00954325],\n",
       "        [0.00628709, 0.02311921, 0.00563783, ..., 0.02287043,\n",
       "         0.01258226, 0.00873444],\n",
       "        ...,\n",
       "        [0.00498838, 0.02577453, 0.00342259, ..., 0.01112233,\n",
       "         0.01365379, 0.01257423],\n",
       "        [0.01290612, 0.004823  , 0.00825663, ..., 0.01328342,\n",
       "         0.01391696, 0.01078378],\n",
       "        [0.00738843, 0.01375407, 0.01063988, ..., 0.01609724,\n",
       "         0.0144048 , 0.00837181]],\n",
       "\n",
       "       [[0.00625808, 0.01749366, 0.00829979, ..., 0.01117567,\n",
       "         0.01201137, 0.01089943],\n",
       "        [0.00422065, 0.00485293, 0.00819373, ..., 0.00649708,\n",
       "         0.0060229 , 0.01082196],\n",
       "        [0.00795718, 0.00475378, 0.00589451, ..., 0.00326457,\n",
       "         0.00500236, 0.0035574 ],\n",
       "        ...,\n",
       "        [0.00625808, 0.01749365, 0.00829979, ..., 0.01117568,\n",
       "         0.01201136, 0.01089944],\n",
       "        [0.00625808, 0.01749366, 0.0082998 , ..., 0.01117564,\n",
       "         0.01201136, 0.01089943],\n",
       "        [0.00625808, 0.01749365, 0.0082998 , ..., 0.01117566,\n",
       "         0.01201137, 0.01089943]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00287307, 0.01509282, 0.00643355, ..., 0.01384042,\n",
       "         0.01738021, 0.01772963],\n",
       "        [0.00583396, 0.01664819, 0.01998362, ..., 0.01617689,\n",
       "         0.02265897, 0.00712846],\n",
       "        [0.00725674, 0.01962087, 0.00621102, ..., 0.00535456,\n",
       "         0.00942853, 0.01189417],\n",
       "        ...,\n",
       "        [0.01761365, 0.0136974 , 0.00435354, ..., 0.00423038,\n",
       "         0.00452884, 0.02300259],\n",
       "        [0.00657506, 0.01614326, 0.00764723, ..., 0.00826249,\n",
       "         0.00910577, 0.00767061],\n",
       "        [0.0028731 , 0.01509298, 0.0064335 , ..., 0.01384036,\n",
       "         0.01737987, 0.01772964]],\n",
       "\n",
       "       [[0.01203399, 0.0102994 , 0.01106663, ..., 0.00812653,\n",
       "         0.00910337, 0.00924959],\n",
       "        [0.00750356, 0.01365545, 0.01271434, ..., 0.04517862,\n",
       "         0.01324685, 0.00676415],\n",
       "        [0.00780281, 0.01268779, 0.00667379, ..., 0.01167675,\n",
       "         0.01258607, 0.01120273],\n",
       "        ...,\n",
       "        [0.01203397, 0.01029939, 0.0110666 , ..., 0.00812652,\n",
       "         0.00910335, 0.00924959],\n",
       "        [0.01203396, 0.01029939, 0.01106662, ..., 0.00812651,\n",
       "         0.00910334, 0.00924959],\n",
       "        [0.01203395, 0.01029938, 0.01106662, ..., 0.00812651,\n",
       "         0.00910335, 0.0092496 ]],\n",
       "\n",
       "       [[0.00493731, 0.03134832, 0.00402203, ..., 0.00711289,\n",
       "         0.00690693, 0.01320266],\n",
       "        [0.00840381, 0.00723604, 0.00335199, ..., 0.01197622,\n",
       "         0.01065005, 0.01934955],\n",
       "        [0.01711012, 0.00635789, 0.00171291, ..., 0.02244323,\n",
       "         0.01119696, 0.04273068],\n",
       "        ...,\n",
       "        [0.01166623, 0.02106227, 0.00523483, ..., 0.00441757,\n",
       "         0.00676873, 0.01105339],\n",
       "        [0.01167694, 0.02048351, 0.00503824, ..., 0.00439963,\n",
       "         0.00691148, 0.01055143],\n",
       "        [0.01100099, 0.01955816, 0.005493  , ..., 0.00446417,\n",
       "         0.00752381, 0.0100325 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(preds[0].detach(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4005a-8425-4bdc-9736-81b826bd3e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
